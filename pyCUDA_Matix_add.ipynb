{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMk3pawXEzY9AbucLGTnDjh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syq-tju/pyCUDA/blob/main/pyCUDA_Matix_add.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ5s47TLp7do",
        "outputId": "26fdcde9-00c8-48fc-b700-2f85b1812fc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2024.1.1-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.10.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.5)\n",
            "Building wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1-cp310-cp310-linux_x86_64.whl size=661204 sha256=19d23bd0667ff7a2d53ff8d2cebd13eeff07f1ffaf468189a0c8d0557e6cc046\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/34/d2/9a349255a4eca3a486d82c79d21e138ce2ccd90f414d9d72b8\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.3 pycuda-2024.1 pytools-2024.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.autoinit\n",
        "import pycuda.driver as drv\n",
        "import numpy as np\n",
        "from pycuda.compiler import SourceModule\n",
        "import time  # 导入time模块用于CPU计时\n",
        "\n",
        "# 定义CUDA kernel\n",
        "mod = SourceModule(\"\"\"\n",
        "__global__ void add_vectors(float *dest, float *a, float *b)\n",
        "{\n",
        "    const int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    dest[i] = a[i] + b[i];\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "# 从module中获取kernel函数\n",
        "add_vectors = mod.get_function(\"add_vectors\")\n",
        "\n",
        "# 设置随机数的数量：2^12\n",
        "num_elements = 2 << 28\n",
        "\n",
        "# 在CPU上生成随机数，赋值给a_host和b_host\n",
        "a_host = np.random.rand(num_elements).astype(np.float32)\n",
        "b_host = np.random.rand(num_elements).astype(np.float32)\n",
        "\n",
        "# 开始CPU计时\n",
        "cpu_start_time = time.time()\n",
        "c_host = a_host + b_host  # CPU上进行向量加法\n",
        "cpu_end_time = time.time()\n",
        "\n",
        "# 显示CPU计算时间\n",
        "print(\"CPU计算时间：\", cpu_end_time - cpu_start_time, \"秒\")\n",
        "\n",
        "# 分配GPU内存并复制数据\n",
        "a_gpu = drv.mem_alloc(a_host.nbytes)\n",
        "b_gpu = drv.mem_alloc(b_host.nbytes)\n",
        "c_gpu = drv.mem_alloc(a_host.nbytes)  # c的结果数组\n",
        "\n",
        "drv.memcpy_htod(a_gpu, a_host)\n",
        "drv.memcpy_htod(b_gpu, b_host)\n",
        "\n",
        "# 设置block和grid的大小\n",
        "block_size = (256, 1, 1)\n",
        "num_blocks = (num_elements + block_size[0] - 1) // block_size[0]\n",
        "\n",
        "# 创建事件以测量GPU时间\n",
        "start_event = drv.Event()\n",
        "end_event = drv.Event()\n",
        "\n",
        "# 开始GPU计时\n",
        "start_event.record()\n",
        "add_vectors(c_gpu, a_gpu, b_gpu, block=(block_size[0], 1, 1), grid=(num_blocks, 1))\n",
        "end_event.record()\n",
        "end_event.synchronize()  # 等待事件完成\n",
        "\n",
        "# 计算并显示GPU计算时间\n",
        "gpu_time = start_event.time_till(end_event) * 1e-3  # 转换为秒\n",
        "print(\"GPU计算时间：\", gpu_time, \"秒\")\n",
        "\n",
        "# 将结果复制回CPU\n",
        "c_host_gpu = np.empty_like(a_host)\n",
        "drv.memcpy_dtoh(c_host_gpu, c_gpu)\n",
        "\n",
        "# 比较结果\n",
        "are_equal = np.allclose(c_host, c_host_gpu)\n",
        "print(\"Are all elements equal?\", are_equal)\n",
        "\n",
        "# 显式释放GPU内存\n",
        "a_gpu.free()\n",
        "b_gpu.free()\n",
        "c_gpu.free()\n"
      ],
      "metadata": {
        "id": "FOT45AkOqYYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.autoinit\n",
        "import pycuda.driver as drv\n",
        "import numpy as np\n",
        "from pycuda.compiler import SourceModule\n",
        "import time\n",
        "\n",
        "# 定义CUDA kernel进行矩阵加法\n",
        "kernel_code = \"\"\"\n",
        "__global__ void matrix_add(float *c, const float *a, const float *b, const int width, const int height)\n",
        "{\n",
        "    int x = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int y = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int index = x + y * width;\n",
        "\n",
        "    if (x < width && y < height) {\n",
        "        c[index] = a[index] + b[index];\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "mod = SourceModule(kernel_code)\n",
        "matrix_add = mod.get_function(\"matrix_add\")\n",
        "\n",
        "def gpu_matrix_add(matrix_add, a, b, block_size=(16, 16, 1)):\n",
        "    width, height = a.shape\n",
        "\n",
        "    a_gpu = drv.mem_alloc(a.nbytes)\n",
        "    b_gpu = drv.mem_alloc(b.nbytes)\n",
        "    c_gpu = drv.mem_alloc(a.nbytes)\n",
        "\n",
        "    drv.memcpy_htod(a_gpu, a)\n",
        "    drv.memcpy_htod(b_gpu, b)\n",
        "\n",
        "    grid_size = ((width + block_size[0] - 1) // block_size[0], (height + block_size[1] - 1) // block_size[1])\n",
        "\n",
        "    start_event = drv.Event()\n",
        "    end_event = drv.Event()\n",
        "\n",
        "    start_event.record()\n",
        "    matrix_add(c_gpu, a_gpu, b_gpu, np.int32(width), np.int32(height), block=block_size, grid=grid_size)\n",
        "    end_event.record()\n",
        "    end_event.synchronize()\n",
        "\n",
        "    gpu_time = start_event.time_till(end_event) * 1e-3  # 转换为秒\n",
        "\n",
        "    c = np.empty_like(a)\n",
        "    drv.memcpy_dtoh(c, c_gpu)\n",
        "\n",
        "    a_gpu.free()\n",
        "    b_gpu.free()\n",
        "    c_gpu.free()\n",
        "\n",
        "    return c, gpu_time\n",
        "\n",
        "# 设置矩阵大小和随机矩阵\n",
        "size = (2<<12, 2<<12)\n",
        "a_host = np.random.rand(*size).astype(np.float32)\n",
        "b_host = np.random.rand(*size).astype(np.float32)\n",
        "\n",
        "# 开始CPU计时\n",
        "cpu_start_time = time.time()\n",
        "c_host = a_host + b_host  # CPU上进行向量加法\n",
        "cpu_end_time = time.time()\n",
        "\n",
        "# 显示CPU计算时间\n",
        "print(\"CPU计算时间：\", cpu_end_time - cpu_start_time, \"秒\")\n",
        "\n",
        "# 使用32x16线程块\n",
        "_, time_optimized_3232 = gpu_matrix_add(matrix_add, a_host, b_host, block_size=(32, 32, 1))\n",
        "print(\"使用32x32线程块的GPU计算时间：\", time_optimized_3232, \"秒\")\n",
        "# 使用32x16线程块\n",
        "_, time_optimized_3216 = gpu_matrix_add(matrix_add, a_host, b_host, block_size=(32, 16, 1))\n",
        "print(\"使用32x16线程块的GPU计算时间：\", time_optimized_3216, \"秒\")\n",
        "# 使用16x16线程块\n",
        "_, time_optimized_1616 = gpu_matrix_add(matrix_add, a_host, b_host, block_size=(16, 16, 1))\n",
        "print(\"使用16x16线程块的GPU计算时间：\", time_optimized_1616, \"秒\")\n",
        "# 使用16x8线程块\n",
        "_, time_optimized_1608 = gpu_matrix_add(matrix_add, a_host, b_host, block_size=(16, 8, 1))\n",
        "print(\"使用16x08线程块的GPU计算时间：\", time_optimized_1608, \"秒\")\n",
        "# 使用8x8线程块\n",
        "_, time_unoptimized = gpu_matrix_add(matrix_add, a_host, b_host, block_size=(8, 8, 1))\n",
        "print(\"使用08x08线程块的GPU计算时间：\", time_unoptimized, \"秒\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvDnE5kht5Wz",
        "outputId": "60f1a957-9ad0-45de-8c87-8a370b01d4e3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: module in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU计算时间： 0.09925436973571777 秒\n",
            "使用32x32线程块的GPU计算时间： 0.0033725121021270753 秒\n",
            "使用32x16线程块的GPU计算时间： 0.0032401599884033204 秒\n",
            "使用16x16线程块的GPU计算时间： 0.003235519886016846 秒\n",
            "使用16x08线程块的GPU计算时间： 0.003271136045455933 秒\n",
            "使用08x08线程块的GPU计算时间： 0.003280479907989502 秒\n"
          ]
        }
      ]
    }
  ]
}